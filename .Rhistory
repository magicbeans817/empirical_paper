lapply(data, class)
#This is definitely troublesome.
#Many of these variables should be factors rather than integers (this is based on basic logic)
#this for cycle converts problematic integer variables to factors and prints their levels
data <- as.data.frame(data)
is.data.frame(data)
for (i in 2:ncol(data)){
data[,i] <- data[,i] %>% factor()
print(levels(data[,i]))
}
data <- read_excel("cancer-patient-data-sets.xlsx") #load the data
#data <- read.csv("survey_lung_cancer.csv") #load the data
#View(data) #take a look at the data
#install.packages("dplyr") #install dplyr, if you do not have it installed
library(dplyr) #load the package
#Now some data manipulation will be performed, so that we know what is the dataset about.
dim(data) # dimension of the dataframe
glimpse(data) #take a glimpse at the data
data %>% colnames() #names of our variables
lapply(data, class)
#This is definitely troublesome.
#Many of these variables should be factors rather than integers (this is based on basic logic)
#this for cycle converts problematic integer variables to factors and prints their levels
data <- as.data.frame(data)
data <- data[,-1]
for (i in 2:ncol(data)){
data[,i] <- data[,i] %>% factor()
print(levels(data[,i]))
}
train_data <- data
train_data <- train_data %>%
filter(Level != "Medium")
levels(train_data$Level)
View(train_data)
levels(train_data$Level)
dim(train_data)
train_data %>%
count(Level)
train_data$Level <- ifelse(train_data$Level == "Low", 0, 1)
#Base model
model1 <- glm(Level ~ ., data = train_data, family = binomial(link = "logit")) #model
summary(model1) #summary
library(foreign)
#require(data.table)
library(data.table)
setwd("C:/Users/Honza/Desktop/r-bakal") #set your working directory
library(readr)
#require(dplyr)
library(dplyr)
#Data for USA, all important variables
data_usa_clean <- select(read_csv("prgusap1.csv"),
GENDER_R, #gender avšak neexistuje, ovšem GENDER_R vyhovuje popisu
AGEG5LFS, EDLEVEL3, #education avšak neexistuje, ovšem logicky by tam podle tabulek
#podle Arntze a ostatních mělo být EDLEVEL3
1207:1216, 1218:1227, 1229:1238, #pvlit, pvnum, pvpsl posloupnosti (středníky),
D_Q03, #D_Q03R avšak neexistuje, ovšem D_Q03 vyhovuje popisu
D_Q06a, #D_Q06aR avšak neexistuje, ovšem D_Q06a vyhovuje popisu
D_Q08a, D_Q12a, #D_Q12aR avšak neexistuje, ovšem D_Q12a vyhovuje popisu
D_Q12c, #D_Q12cR avšak neexistuje, ovšem D_Q12c vyhovuje popisu
D_Q16a, #D_Q16aR avšak neexistuje, ovšem D_Q16a vyhovuje popisu
G_Q04, #G_Q04R avšak neexistuje, ovšem G_Q04 vyhovuje popisu
G_Q06, #G_Q06R avšak neexistuje, ovšem G_q06 vyhovuje popisu
F_Q01b, F_Q02a, F_Q02b, F_Q02c, F_Q02d, F_Q02e, F_Q03a, F_Q03b,
F_Q03c, F_Q04a,F_Q04b, F_Q05a, F_Q05b, F_Q06b, F_Q06c, F_Q07a,
F_Q07b, G_Q01a, G_Q01d, G_Q01e, G_Q01f, G_Q02b, G_Q02d, G_Q03c,
G_Q03h, G_Q05c, G_Q05g, G_Q05h, YEARLYINCPR, #YEARLYINCPRR neex. avšak YEARLYINCPR vyhovuje
ISCO2C, #tohle v tabulce chybí, jde o ISCO zaměstnání (2 digits)
SPFWT0 #final sample weight
)
#Exclude armed forces, observations with missing occupational codes etc.
data_usa_clean_excl <- subset(data_usa_clean, ISCO2C != "0" & ISCO2C != "01" & ISCO2C != "02" &
ISCO2C != "03" & ISCO2C != "9995" & ISCO2C != "9996" &
ISCO2C != "9997" & ISCO2C != "9998" & ISCO2C != "9999" &
ISCO2C != ".") #excl armed forces, 1 - digit ISCO and missing val
#View(data_usa_clean_excl)
#Count how many observations are there for each isco, just to get some idea about the data
h <- factor(data_usa_clean_excl$ISCO2C)
levels(h) #kontrola, jestli armfor, 1 - digit and missing val zmizely
nrow(data_usa_clean_excl)
data_usa_clean_excl_cnttbl <- (data_usa_clean_excl %>%
count(ISCO2C))
#View(data_usa_clean_excl_cnttbl)
#################################################################################################################
#SOC codes should be converted to isco
library(readxl)
occ_output <- read_excel("occ_output.xlsx") #dataset - probability by Frey & Osborne
class(occ_output$SOC)
library(stringr)
occ_output$soc10 <- str_remove_all(occ_output$SOC, "[-]")
conversion <- read.dta("soc10_isco08.dta") #crosswalk download from websites of University of Warsaw
#View(conversion)
#View(occ_output)
#occ_output_merged is the version of occ_output, where SOC's were converted to isco but not vice versa
occ_output <- as.data.table(occ_output)
conversion <- as.data.table(conversion)
occ_output$soc10 <- factor(occ_output$soc10)
conversion$soc10 <-factor(conversion$soc10)
#Konverze (viz řádek dolů) je hotová, avšak asi takhle nefunguje, víš co!!!
occ_output_merged <- merge.data.table(x = occ_output, y = conversion,
by.x="soc10",
by.y = "soc10", all = TRUE, all.x = FALSE,
all.y = FALSE, allow.cartesian=FALSE)
#View(occ_output_merged)
#This step is necessary because we are going to work with only first two decimals of ISCO
occ_output_merged$isco08 <- substr(occ_output_merged$isco08, 1, nchar(occ_output_merged$isco08)-2)
#################################################################################################################
#This is necessary so that the initial weights are created - we count number of duplicates of ISCO
library(stringr)
#require(tidyr)
library(tidyr)
class(occ_output_merged$isco08)
#View(occ_output_merged)
nrow(occ_output_merged)
countisco <- (occ_output_merged %>%
count(isco08))
class(occ_output_merged$isco08)
countisco$initialweights <- countisco$n^(-1) #third column, initial weigths for our model
head(countisco)
countisco <- as.data.table(countisco)
#For assigning initial weights, firstly create column full of nulls
data_usa_clean_excl <- as.data.table(data_usa_clean_excl)
data_usa_clean_excl$initialweights =0 #create new column full of NULLS
head(data_usa_clean_excl$initialweights)
ncol(data_usa_clean_excl)
#To assign initial weight to each observation, this cycle is created (not very elegant or fast, but works)
for (i in 1:length(data_usa_clean_excl$ISCO2C)) {
for (j in 1:length(countisco$isco08)) {
if(data_usa_clean_excl[i,'ISCO2C'] == countisco[j,'isco08']) {
data_usa_clean_excl[i,'initialweights'] <- countisco[j,'n']
break(next)
}
}
}
#View(data_usa_clean_excl)
#require(WriteXLS)
library(WriteXLS)
# Dataset below is created so that first 100 lines of code do not have to run first 100 lines of code every time,
# especially the for cycle takes some time, so you can just load this after it is created
write.csv(data_usa_clean_excl, "data_usa_clean_excl.csv")
#data_usa_clean_excl <- select(read_csv("data_usa_clean_excl.csv"), -X1)
#
occ_output_merged <- as.data.table(occ_output_merged)
occ_output_merged <- rename(occ_output_merged, ISCO2C = isco08)
class(occ_output_merged$ISCO2C)
class(data_usa_clean_excl$ISCO2C)
levels(occ_output_merged$ISCO2C)
length(levels(occ_output_merged$ISCO2C))
data_usa_clean_excl$ISCO2C <- factor(data_usa_clean_excl$ISCO2C)
occ_output_merged$ISCO2C <- factor(occ_output_merged$ISCO2C)
#View(occ_output_merged)
# This is where duplicate observation dataset is created - by merging these two datasets
data_usa_merged <- merge.data.table(x = data_usa_clean_excl, y = occ_output_merged,
by.x="ISCO2C",
by.y = "ISCO2C", all = TRUE, all.x = TRUE,
all.y = TRUE, allow.cartesian=TRUE)
nrow(data_usa_merged)
#View(data_usa_merged)
head(data_usa_merged)
data_usa_merged$Propability
# Formula for my_model
flipitydopity <- c("GENDER_R", #gender avšak neexistuje, ovšem GENDER_R vyhovuje popisu
"AGEG5LFS", "EDLEVEL3", #education avšak neexistuje, ovšem logicky by tam podle tabulek
#podle Arntze a ostatních mělo být EDLEVEL3
"PVLIT1","PVLIT2","PVLIT3","PVLIT4","PVLIT5","PVLIT6","PVLIT7","PVLIT8","PVLIT9","PVLIT10",
"PVNUM1","PVNUM2","PVNUM3","PVNUM4","PVNUM5","PVNUM6","PVNUM7","PVNUM8","PVNUM9","PVNUM10",
"PVPSL1","PVPSL2","PVPSL3","PVPSL4","PVPSL5","PVPSL6","PVPSL7","PVPSL8","PVPSL9","PVPSL10", #pvlit, pvnum, pvpsl posloupnosti (středníky),
"D_Q03", #D_Q03R avšak neexistuje, ovšem D_Q03 vyhovuje popisu
"D_Q06a", #D_Q06aR avšak neexistuje, ovšem D_Q06a vyhovuje popisu
"D_Q08a", "D_Q12a", #D_Q12aR avšak neexistuje, ovšem D_Q12a vyhovuje popisu
"D_Q12c", #D_Q12cR avšak neexistuje, ovšem D_Q12c vyhovuje popisu
"D_Q16a", #D_Q16aR avšak neexistuje, ovšem D_Q16a vyhovuje popisu
"G_Q04", #G_Q04R avšak neexistuje, ovšem G_Q04 vyhovuje popisu
"G_Q06", #G_Q06R avšak neexistuje, ovšem G_q06 vyhovuje popisu
"F_Q01b", "F_Q02a", "F_Q02b", "F_Q02c", "F_Q02d", "F_Q02e", "F_Q03a", "F_Q03b",
"F_Q03c", "F_Q04a","F_Q04b", "F_Q05a", "F_Q05b", "F_Q06b", "F_Q06c", "F_Q07a",
"F_Q07b", "G_Q01a", "G_Q01d", "G_Q01e", "G_Q01f", "G_Q02b", "G_Q02d", "G_Q03c",
"G_Q03h", "G_Q05c", "G_Q05g", "G_Q05h", "YEARLYINCPR")
fmla <- as.formula(paste("Propability ~", paste(flipitydopity, collapse= "+")))
fmla
# Exclude missing observations
data_usa_clean_excl <- data_usa_clean_excl[complete.cases(data_usa_clean_excl), ]
nrow(data_usa_clean_excl)
#Create empty column full on NA's for predictions for original dataset, bullshit excluded
data_usa_clean_excl$predictions = NA
nrow(data_usa_clean_excl)
#Exclude missing observations
data_usa_merged <- data_usa_merged[complete.cases(data_usa_merged), ]
nrow(data_usa_merged)
# Getting ready for iteration:
# Create dataset for weights
weights <- data.frame(data_usa_merged$initialweights^-1)
head(weights)
# Adjusting levels so later our model is able to predict on czech dataset
data_usa_merged$D_Q12a <- factor(data_usa_merged$D_Q12a)
levels(data_usa_merged$D_Q12a)
spec <- select(read_csv("prgczep1.csv"), D_Q12a, D_Q03)
spec$D_Q12a <- factor(spec$D_Q12a)
levels(spec$D_Q12a)
levels_both <- unique(c(levels(data_usa_merged$D_Q12a),levels(spec$D_Q12a)))
levels_both
levels(data_usa_merged$D_Q12a) <- levels_both
levels(data_usa_merged$D_Q12a)
is.factor(data_usa_merged$D_Q12a)
table(data_usa_merged$D_Q12a)
####################################################################################################################
# Set your values for convergence
eps <- 10^(-10) #works as epsilon in formula for convergence of sequences in math
frac <- 0.999 #fraction of total number of weights for which eps holds
#You can start iterating
i <- 1
repeat{
options(warn=-1) #negative value - warnings are not shown
print(i) #so you know, how many iterations have gone by
my_model <- glm(fmla, data = data_usa_merged, family = quasibinomial('logit'),
na.action = na.exclude, weights = data_usa_merged$SPFWT0 * weights[,i])
#Calculate nominator for new weights
data_usa_merged$predictions <- predict.glm(my_model, data_usa_merged, type = "response" ) #Calculate predictions
length(data_usa_merged$predictions)
data_usa_merged$nom <- dnorm(data_usa_merged$predictions
- data_usa_merged$Propability, mean = 0, sd = 1) #density function, normal
#Calculate denominator
my_table <- aggregate(data_usa_merged$nom, by = list(data_usa_merged$PVLIT1), FUN = sum)
colnames(my_table) <- c("Group.1","denom")
# Assign denominators to observations - tahle část je svým způsobem pofidérní, protože přiřazování funguje na
# základě proměnné PVLIT1, ne indexů. Avšak PVLIT1 má v data_usa_clean_excl datasetu unikátní hodnoty -
# žádná tam není víckrát. V rámci modelu hodnoty nominatoru jsou různé, ale denominator má pro všechny duplicates
# stejnou hodnotu, proto to můžu takhle z mergovat (místo toho, aby se to dělalo for cykly). Počet řádků zůstává
# stejný - což znamená, že to nejspíš funguje tak, jak má.
data_usa_merged <- merge.data.table(x = data_usa_merged, y = my_table, #merging should be based on indexes or
by.x="PVLIT1",                     #something different than PVLIT1. On the
by.y = "Group.1", all = FALSE, all.x = FALSE, #hand, PVLIT1 can be used as
all.y = FALSE, allow.cartesian=TRUE) #its values are unique in PIAAC.
#Calculate new weights
weights[,i+1] <- data_usa_merged$nom / data_usa_merged$denom
#Calculate "convergency vector"
conv <- abs(weights[,i+1]-weights[,i])
cond <- length(subset(conv, subset = conv < eps))
if(cond/nrow(weights) > frac){
print(summary(my_model))
print(paste("Iteration ended after",i,"iterations."))
i <- i+1
data_usa_merged <- select(data_usa_merged, -nom, -denom)
break
} else {
data_usa_merged <- select(data_usa_merged, -predictions, -nom, -denom) #aby to mohlo jít od začátku, musí se vymazat
i <- i+1
}
}
levels(data_usa_merged$D_Q12a)
#turns everything to factors and prints their levels
for (i in 2:ncol(data)){
data[,i] <- data[,i] %>% factor()
print(levels(data[,i]))
}
#PROLOGUE #################################################################################
setwd("C:/Users/Honza/Desktop/Empirical_paper/empirical_paper") #set your working directory
data <- read.csv("survey_lung_cancerdata.csv") #load the data
#data <- read.csv("survey_lung_cancer.csv") #load the data
#View(data) #take a look at the data
#install.packages("dplyr") #install dplyr, if you do not have it installed
library(dplyr) #load the package
#SECTION 1 ################################################################################
#Now some data manipulation will be performed, so that we know what is the dataset about.
dim(data) # dimension of the dataframe
glimpse(data) #take a glimpse at the data
data %>% colnames() #names of our variables
#This for cycle prints class of every variable (glimpse function already gave us this
#information, this is just another way to acquire it)
for (i in 1:ncol(data)){
print(class(data[,i]))
}
#This is definitely troublesome.
#Many of these variables should be factors rather than integers (this is based on basic logic)
#this for cycle converts problematic integer variables to factors and prints their levels
for (i in 3:ncol(data)){
data[,i] <- data[,i] %>% factor()
print(levels(data[,i]))
}
data$LUNG_CANCER <- ifelse(data$LUNG_CANCER == "YES", 1,0) #converts YES or NO to numeric
data$LUNG_CANCER %>% #checks what class is the variable for cancer
class()
data %>% #counts number of observations with and without cancer
count(LUNG_CANCER)
#We are especially interested in impacts of smoking on lung cancer:
data %>%
count(SMOKING, wt = LUNG_CANCER)
#We can put these two together:
tabulka <- data %>%
count(SMOKING, LUNG_CANCER)
#print the table, so we can put it in the paper
#Tajna myskavec na delani ala texovych tabulek
#install.packages(xtable)
library(xtable)
tabulka <- as.matrix(tabulka)
pocet <- as.numeric(as.vector(tabulka[,"n"]))
tabulka1 <- matrix(pocet, nrow = 2, ncol = 2, byrow = TRUE,
dimnames = list(c("Non-smokers","Smokers"),c("Cancer-free","Cancer")))
tabulka1 <- as.data.frame(tabulka1)
tabulka1
print(xtable(tabulka1, caption = "Numbers of smokers and non-smokers in the dataset with and without cancer",
digits = 0, type = "latex"), file = "table1.tex")
#Oh, shit, it seems that our dataset is not unbiased random sample from population of
#lung-cancer patients, as 80% to 90% of lung cancer cases are associated with smoking.
#What now then? I believe, that we can continue to work nevertheless, because this is
#sample of people from population who fill out online questionnare. There are various possible
#explanations for why these people are not and even cannot be random sample of patients
#with lung cancer. However, I believe we can still use the data, only the predictive
#power of our model will not be general. It will be associated with specific subsample
#of cancer patients.
#SECTION 2 ################################################################################
#Here we will do some actual modelling. We choose generalized linear model due to binary
#nature of our response variable.
#As we have shown before, only 12.6% of our observations do not suffer from lung cancer.
#Therefore we choose logit, as it has fatter tails and is better at modelling outliers.
#Let's create formula for our model:
flipitydopity <- c("GENDER","AGE", "SMOKING","YELLOW_FINGERS","ANXIETY","PEER_PRESSURE",
"CHRONIC.DISEASE","FATIGUE","ALLERGY","WHEEZING","ALCOHOL.CONSUMING",
"COUGHING","SHORTNESS.OF.BREATH","SWALLOWING.DIFFICULTY","CHEST.PAIN")
fmla <- as.formula(paste("LUNG_CANCER ~", paste(flipitydopity, collapse= "+")))
fmla
#The model
model1 <- glm(fmla, data = data, family = binomial(link = "logit")) #model
summary(model1) #summary
#Some of our variables did not prove themselves to be significant.
#However, many of these variables are connected to each other, therefore we will now consider
#adjusting our model and adding interactions between variables. We can also substract several
#variables as insignificant. For example, gender does not seem to play a significant role
#in matter of having cancer. Also anxiety might be connected to lung cancer, however it makes
#sense that this implication is not strong, asmuch larger share of population suffers
#from anxiety than from lung cancer.
#Also multicollinearity between e.g. smoking and yellow fingers
#Lets make a vector of variables we will exclude:
exclude <- c("ANXIETY","WHEEZING","SHORTNESS.OF.BREATH","CHEST.PAIN","GENDER","AGE")
flipitydopity2 <- flipitydopity[!flipitydopity %in% exclude]
flipitydopity2
#New formula:
fmla2 <- as.formula(paste("LUNG_CANCER ~", paste(flipitydopity2, collapse= "+")))
fmla2
#New model
model2 <- glm(fmla2, data = data, family = binomial(link = "logit")) #model with interactions
summary(model2)
#PROLOGUE #################################################################################
setwd("C:/Users/Honza/Desktop/Empirical_paper/empirical_paper") #set your working directory
library(readxl)
data <- read_excel("cancer-patient-data-sets.xlsx") #load the data
#data <- read.csv("survey_lung_cancer.csv") #load the data
#View(data) #take a look at the data
#install.packages("dplyr") #install dplyr, if you do not have it installed
library(dplyr) #load the package
#SECTION 1 ################################################################################
#Now some data manipulation will be performed, so that we know what is the dataset about.
dim(data) # dimension of the dataframe
glimpse(data) #take a glimpse at the data
data %>% colnames() #n
lapply(data, class)
#This is definitely troublesome.
#Many of these variables should be factors rather than integers (this is based on basic logic)
#this for cycle converts problematic integer variables to factors and prints their levels
data <- as.data.frame(data) #turn it to dataframe
is.data.frame(data)
data <- data[,-1] #get rid of patient id
#turns everything to factors and prints their levels
for (i in 2:ncol(data)){
data[,i] <- data[,i] %>% factor()
print(levels(data[,i]))
}
#create train dataset without medium probability of cancer
train_data <- data
train_data <- train_data %>%
filter(Level != "Medium")
levels(train_data$Level)
dim(train_data)
train_data %>%
count(Level)
train_data$Level <- ifelse(train_data$Level == "Low", 0, 1)
#Base model
model1 <- glm(Level ~ ., data = train_data, family = binomial(link = "logit")) #model
summary(model1) #summary
#PROLOGUE #################################################################################
setwd("C:/Users/Honza/Desktop/Empirical_paper/empirical_paper") #set your working directory
data <- read.csv("survey_lung_cancerdata.csv") #load the data
#data <- read.csv("survey_lung_cancer.csv") #load the data
#View(data) #take a look at the data
#install.packages("dplyr") #install dplyr, if you do not have it installed
library(dplyr) #load the package
#SECTION 1 ################################################################################
#Now some data manipulation will be performed, so that we know what is the dataset about.
dim(data) # dimension of the dataframe
glimpse(data) #take a glimpse at the data
data %>% colnames() #names of our variables
#This for cycle prints class of every variable (glimpse function already gave us this
#information, this is just another way to acquire it)
for (i in 1:ncol(data)){
print(class(data[,i]))
}
#This is definitely troublesome.
#Many of these variables should be factors rather than integers (this is based on basic logic)
#this for cycle converts problematic integer variables to factors and prints their levels
for (i in 3:ncol(data)){
data[,i] <- data[,i] %>% factor()
print(levels(data[,i]))
}
data$LUNG_CANCER <- ifelse(data$LUNG_CANCER == "YES", 1,0) #converts YES or NO to numeric
data$LUNG_CANCER %>% #checks what class is the variable for cancer
class()
data %>% #counts number of observations with and without cancer
count(LUNG_CANCER)
#We are especially interested in impacts of smoking on lung cancer:
data %>%
count(SMOKING, wt = LUNG_CANCER)
#We can put these two together:
tabulka <- data %>%
count(SMOKING, LUNG_CANCER)
#print the table, so we can put it in the paper
#Tajna myskavec na delani ala texovych tabulek
#install.packages(xtable)
library(xtable)
tabulka <- as.matrix(tabulka)
pocet <- as.numeric(as.vector(tabulka[,"n"]))
tabulka1 <- matrix(pocet, nrow = 2, ncol = 2, byrow = TRUE,
dimnames = list(c("Non-smokers","Smokers"),c("Cancer-free","Cancer")))
tabulka1 <- as.data.frame(tabulka1)
tabulka1
print(xtable(tabulka1, caption = "Numbers of smokers and non-smokers in the dataset with and without cancer",
digits = 0, type = "latex"), file = "table1.tex")
#Oh, shit, it seems that our dataset is not unbiased random sample from population of
#lung-cancer patients, as 80% to 90% of lung cancer cases are associated with smoking.
#What now then? I believe, that we can continue to work nevertheless, because this is
#sample of people from population who fill out online questionnare. There are various possible
#explanations for why these people are not and even cannot be random sample of patients
#with lung cancer. However, I believe we can still use the data, only the predictive
#power of our model will not be general. It will be associated with specific subsample
#of cancer patients.
#SECTION 2 ################################################################################
#Here we will do some actual modelling. We choose generalized linear model due to binary
#nature of our response variable.
#As we have shown before, only 12.6% of our observations do not suffer from lung cancer.
#Therefore we choose logit, as it has fatter tails and is better at modelling outliers.
#Let's create formula for our model:
flipitydopity <- c("GENDER","AGE", "SMOKING","YELLOW_FINGERS","ANXIETY","PEER_PRESSURE",
"CHRONIC.DISEASE","FATIGUE","ALLERGY","WHEEZING","ALCOHOL.CONSUMING",
"COUGHING","SHORTNESS.OF.BREATH","SWALLOWING.DIFFICULTY","CHEST.PAIN")
fmla <- as.formula(paste("LUNG_CANCER ~", paste(flipitydopity, collapse= "+")))
fmla
#The model
model1 <- glm(fmla, data = data, family = binomial(link = "logit")) #model
summary(model1) #summary
#Some of our variables did not prove themselves to be significant.
#However, many of these variables are connected to each other, therefore we will now consider
#adjusting our model and adding interactions between variables. We can also substract several
#variables as insignificant. For example, gender does not seem to play a significant role
#in matter of having cancer. Also anxiety might be connected to lung cancer, however it makes
#sense that this implication is not strong, asmuch larger share of population suffers
#from anxiety than from lung cancer.
#Also multicollinearity between e.g. smoking and yellow fingers
#Lets make a vector of variables we will exclude:
exclude <- c("ANXIETY","WHEEZING","SHORTNESS.OF.BREATH","CHEST.PAIN","GENDER","AGE")
flipitydopity2 <- flipitydopity[!flipitydopity %in% exclude]
flipitydopity2
#New formula:
fmla2 <- as.formula(paste("LUNG_CANCER ~", paste(flipitydopity2, collapse= "+")))
fmla2
#New model
model2 <- glm(fmla2, data = data, family = binomial(link = "logit")) #model with interactions
summary(model2)
tabulka <- data %>%
count(SMOKING, YELLOW_FINGERS)
tabulka <- data %>%
count(SMOKING, YELLOW_FINGERS)
#PROLOGUE #################################################################################
setwd("C:/Users/Honza/Desktop/Empirical_paper/empirical_paper") #set your working directory
data <- read.csv("survey_lung_cancerdata.csv") #load the data
#data <- read.csv("survey_lung_cancer.csv") #load the data
#View(data) #take a look at the data
#install.packages("dplyr") #install dplyr, if you do not have it installed
library(dplyr) #load the package
#SECTION 1 ################################################################################
#Now some data manipulation will be performed, so that we know what is the dataset about.
dim(data) # dimension of the dataframe
glimpse(data) #take a glimpse at the data
data %>% colnames() #names of our variables
#This for cycle prints class of every variable (glimpse function already gave us this
#information, this is just another way to acquire it)
for (i in 1:ncol(data)){
print(class(data[,i]))
}
#This is definitely troublesome.
#Many of these variables should be factors rather than integers (this is based on basic logic)
#this for cycle converts problematic integer variables to factors and prints their levels
for (i in 3:ncol(data)){
data[,i] <- data[,i] %>% factor()
print(levels(data[,i]))
}
data$LUNG_CANCER <- ifelse(data$LUNG_CANCER == "YES", 1,0) #converts YES or NO to numeric
data$LUNG_CANCER %>% #checks what class is the variable for cancer
class()
data %>% #counts number of observations with and without cancer
count(LUNG_CANCER)
#We are especially interested in impacts of smoking on lung cancer:
data %>%
count(SMOKING, wt = LUNG_CANCER)
#We can put these two together:
tabulka <- data %>%
count(SMOKING, LUNG_CANCER)
tabulka <- data %>%
count(SMOKING, YELLOW_FINGERS)
#We can put these two together:
tabulka <- data %>%
count(SMOKING, LUNG_CANCER)
hist(data$AGE, data$LUNG_CANCER)
plot(data$AGE, data$LUNG_CANCER)
"A"*2
